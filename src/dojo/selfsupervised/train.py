import os
import argparse
import random
import warnings
from typing import Union

import coolname
import torchvision
from torchvision.transforms import v2
from aim.pytorch_lightning import AimLogger
from dotenv import load_dotenv

import torch
import lightning.pytorch as pl
from lightning.pytorch.callbacks import ModelCheckpoint
from lightning.pytorch.tuner import Tuner

# set import paths to project root
if __name__ == '__main__':
    import sys, pathlib
    PROJECT_ROOT = pathlib.Path(__file__).parent.parent.parent.absolute()
    if sys.path[0] != str(PROJECT_ROOT): sys.path.insert(0, str(PROJECT_ROOT))

from multiclass.models import check_model_name, get_model_base_transforms, get_namebrand_model, get_model_resize
from multiclass.callbacks import LogNormalizedLoss, BarPlotMetricAim, PlotConfusionMetricAim, PlotPerclassDropdownAim
from multiclass.train import setup_aimlogger

from selfsupervised.datasets import IfcbDatamodule
from selfsupervised.models import SimCLR, VICReg, PMSN, DINO

def argparse_init(parser=None):
    if parser is None:
        parser = argparse.ArgumentParser(description='Train an image classifier!')

    # DATASET #
    dataset = parser.add_argument_group(title='Dataset', description=None)
    dataset.add_argument('--trainlist', required=True, help='A text file, one ifcb bin-directory per line.')
    dataset.add_argument('--classlist', help='A text file, each line is a class label (the label order is significant)')
    dataset.add_argument('--vallist', help='A text file, one sample per line, each sample has a class-index and image path')
    dataset.add_argument('--knnlist', help='Embeddings VALLIST samples will be k-nearest-neighbored with')
    dataset.add_argument('--knn-k', metavar='K', type=int, default=11, help='Number K of nearest-neighbors to check. Default is 11')
    dataset.add_argument('--shuffle-buffer', type=int, default=1000, help='How many ROIs to gather before shuffling. 1 to disable buffer, 0 to disable shuffling. Default is 1000 ')

    # TRACKING #
    aimstack = parser.add_argument_group(title='AimLogger', description=None)
    aimstack.add_argument('--run', help='The name of this run. A run name is automatically generated by default')
    aimstack.add_argument('--experiment', help='The broader category/grouping this RUN belongs to')
    aimstack.add_argument('--note', help='Add any kind of note or description to the trained model. Make sure to use quotes "around your message."')
    aimstack.add_argument('--repo', help='Aim repo path. Also see: Aim environment variables.')
    aimstack.add_argument('--artifacts-location', help='Aim Artifacts location. Also see: Aim environment variables.')
    #aimstack.add_argument('--plot', nargs='+', action='append', ...)
    #aimstack.add_argument('--callback', nargs='+', action='append', ...)
    #aimstack.add_argument('--metric', nargs='+', action='append', ...)

    # HYPER PARAMETERS #
    model = parser.add_argument_group(title='Model Parameters')
    model.add_argument('--method', required=True, choices=('SimCLR','VICReg','PMSN','DINO'), help='Self-supervised Learning methodolgy')
    model.add_argument('--model-name', help='Model Class/Module Name or torch model checkpoint file', required=True)  # TODO checkopint file, also check loading from s3
    model.add_argument('--weights', default='DEFAULT', help='''Specify a model's weights. Either "DEFAULT", some specific identifier, or "None" for no-pretrained-weights''')
    model.add_argument('--seed', type=int, help='Set a specific seed for deterministic output')
    model.add_argument('--batch', dest='batch_size', metavar='SIZE', default=256, type=int, help='Number of images per batch. Defaults is 256')

    epochs = parser.add_argument_group(title='Epoch Parameters')
    epochs.add_argument('--epoch-max', metavar='MAX', default=100, type=int, help='Maximum number of training epochs. Default is 100')
    epochs.add_argument('--epoch-min', metavar='MIN', default=10, type=int, help='Minimum number of training epochs. Default is 10')
    epochs.add_argument('--epoch-stop', metavar='STOP', default=10, type=int, help='Early Stopping: Number of epochs following a best-epoch after-which to stop training. Set STOP=0 to disable. Default is 10')

    # UTILITIES #
    parser.add_argument('--checkpoints-path', default='./experiments')
    parser.add_argument('--autobatch', nargs='?', default=False, const='power', choices=['power','binsearch'], help='Auto-Tunes batch_size prior to training/inference.')
    parser.add_argument('--autobatch-max', type=int, help='Disallow autobatch for setting ')
    parser.add_argument('--workers', dest='num_workers', metavar='N', type=int, help='Total number of dataloader worker threads. If set, overrides --workers-per-gpu')
    parser.add_argument('--workers_per_gpu', metavar='N', default=4, type=int, help='Number of data-loading threads per GPU. 4 per GPU is typical. Default is 4')
    parser.add_argument('--fast-dev-run', default=False, action='store_true')
    parser.add_argument('--env', metavar='FILE', nargs='?', const=True, help='Environment Variables file. If set but not specified, attempts to find a parent .env file')
    parser.add_argument('--gpus', nargs='+', type=int, help=argparse.SUPPRESS) # CUDA_VISIBLE_DEVICES
    parser.add_argument('--val-interval', default=1.0, type=float, help='How often to check the validation set. A float in the range [0.0, 1.0] checks after a fraction of the training epoch. An int checks after a fixed number of training batches. Default is "1.0"')
    return parser


def argparse_runtime_args(args):
    # Record GPUs
    if not args.gpus:
        args.gpus = [int(gpu) for gpu in os.environ.get('CUDA_VISIBLE_DEVICES','UNSET').split(',') if gpu not in ['','UNSET']]

    if args.env:
        load_dotenv(override=True) if args.env is True else load_dotenv(args.env, override=True)
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str,args.gpus))  # reset if not included in .env

    if not args.num_workers:
        args.num_workers = len(args.gpus)*args.workers_per_gpu

    # Record Version
    try:
        with open('VERSION') as f:
            args.version = f.read().strip()
    except FileNotFoundError:
        args.version = None

    # Set Seed. If args.seed is 0 ie None, a random seed value is used and stored
    if args.seed is None:
        args.seed = random.randint(1,2**32-1)
    args.seed = pl.seed_everything(args.seed)

    if args.weights.lower() == 'none':
        args.weights = None

    if not args.run:
        args.run = coolname.generate_slug(2)
        print(f'RUN: {args.run}')

    if args.artifacts_location and os.path.isdir(args.artifacts_location):
        args.artifacts_location = f'file://{os.path.abspath(args.artifacts_location)}'
    if 'AIM_ARTIFACTS_URI' in os.environ and os.environ['AIM_ARTIFACTS_URI']:
        if os.path.isdir(os.environ['AIM_ARTIFACTS_URI']):
            os.environ['AIM_ARTIFACTS_URI'] = f'file://{os.path.abspath(os.environ["AIM_ARTIFACTS_URI"])}'

    if args.vallist or args.knnlist or args.classlist:
        if not (args.vallist and args.knnlist and args.classlist):
            raise ValueError('Incomplete Mutually-Inclusive args: --vallist --knnlist --classlist')

    if args.val_interval > 1:
        args.val_interval = int(args.val_interval)


def setup_model_and_datamodule(args):

    # Model-dependant Dataset Params
    args.model_name = check_model_name(args.model_name)
    resize = get_model_resize(args.model_name)
    common_tf_args = dict(input_size=resize, vf_prob=0.5, hf_prob=0.5, cj_prob=0.8, min_scale=0.2,
                          gaussian_blur=0, random_gray_scale=0, normalize=None,)
    if args.method == 'SimCLR':
        SSLModule = SimCLR
        from lightly.transforms import SimCLRTransform
        transform = SimCLRTransform(**common_tf_args)

    elif args.method == 'VICReg':
        SSLModule = VICReg
        from lightly.transforms import VICRegTransform
        transform = VICRegTransform(**common_tf_args, solarize_prob=0.1)

    elif args.method == 'PMSN':
        SSLModule = PMSN
        from lightly.transforms import MSNTransform
        [common_tf_args.pop(key) for key in 'input_size min_scale normalize'.split()]
        transform = MSNTransform(**common_tf_args)

    elif args.method == 'DINO':
        SSLModule = DINO
        from lightly.transforms import DINOTransform
        [common_tf_args.pop(key) for key in 'input_size min_scale normalize gaussian_blur'.split()]
        transform = DINOTransform( **common_tf_args,
            global_crop_size = 224,
            global_crop_scale = (0.4, 1.0),
            local_crop_size = 96,
            local_crop_scale = (0.05, 0.4),
            n_local_views = 6,
            gaussian_blur=(0,0,0),
            )

    else:
        raise ValueError(f'SSL Method "{args.method}" UNKNOWN')

    eval_transform = None
    if args.classlist:
        eval_transforms = get_model_base_transforms(args.model_name)
        eval_transform = v2.Compose(eval_transforms)

    # Datamodule
    datamodule = IfcbDatamodule(args.trainlist, transform,
                                args.knnlist, args.vallist,
                                args.classlist, eval_transform,
                                batch_size=args.batch_size, num_workers=args.num_workers,
                                shuffler_buffer_size=args.shuffle_buffer, use_len=True)
    knn_dataloader = datamodule.knn_dataloader() if args.knnlist else []
    knn_minclasscount = min(knn_dataloader.dataset.count_perclass.values())
    if args.knn_k > knn_minclasscount:
        warnings.warn(f'args.knn_k {args.knn_k} > {knn_minclasscount}, the number of class instances of the smallest class. This will impact performance metrics.')

    model = SSLModule(args.model_name, args.weights,
                      output_dim=256, hidden_dim='input_dim',
                      knn_dataloader=knn_dataloader, knn_k=args.knn_k)
    return model, datamodule


def main(args):
    torch.set_float32_matmul_precision('medium')

    ## Setup Model & Data Module ##
    model, datamodule = setup_model_and_datamodule(args)

    ## Setup Epoch Logger ##
    # val_/train_ already handled by default
    contexts = dict(averaging={'macro': '_macro', 'micro': '_micro', 'weighted': '_weighted',
                               'none': '_perclass'},  # f1, precision, recall, accuracy
                    )
    logger = setup_aimlogger(args, contexts)

    ## Setup Callbacks ##
    callbacks = []

    plotting_callbacks = [
        BarPlotMetricAim('f1_perclass', order_by='f1_perclass'),

        PlotConfusionMetricAim(order_by='classes', normalize=True),
        PlotConfusionMetricAim(order_by='f1_perclass', normalize=True),

        PlotPerclassDropdownAim(),
    ]
    callbacks.extend(plotting_callbacks)

    # Checkpointing
    # https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html
    # https://lightning.ai/docs/pytorch/stable/common/checkpointing_advanced.html
    hashid = logger.experiment.hash if isinstance(logger,AimLogger) else logger[0].experiment.hash
    runid = args.run
    chkpt_path = os.path.join(args.checkpoints_path, args.experiment, args.run)
    ckpt_callback = ModelCheckpoint(
        dirpath=chkpt_path, filename='loss-{val_normloss:3.3f}_ep-{epoch:03.0f}',
        monitor='val_loss', mode='min', save_last='link', save_top_k=3,
        auto_insert_metric_name=False)
    callbacks.append(LogNormalizedLoss())
    callbacks.append(ckpt_callback)

    ## Setup Trainer  ##
    trainer = pl.Trainer(num_sanity_val_steps=0,
                         deterministic=True,
                         accelerator='auto', devices='auto', num_nodes=1,
                         max_epochs=args.epoch_max, min_epochs=args.epoch_min,
                         precision='16',
                         logger=logger,
                         log_every_n_steps=-1,
                         callbacks=callbacks,
                         fast_dev_run=args.fast_dev_run,
                         default_root_dir='/tmp/classifier',
                         val_check_interval=args.val_interval,  # for very large datasets
                        )

    # auto-tune batch-size
    if args.autobatch:
        tuner = Tuner(trainer)
        found_batch_size = tuner.scale_batch_size(model, datamodule=datamodule,
            mode=args.autobatch, method='fit', max_trials=10, init_val=args.batch_size)
        args.batch_size_init, args.batch_size = args.batch_size, min([found_batch_size, args.autobatch_max or float('inf')])

    # Saving input artifacts
    if trainer.logger.experiment.artifacts_uri:
        if os.path.isfile(args.trainlist):
            trainer.logger.experiment.log_artifact(args.trainlist, name=os.path.basename(args.trainlist), block=True)
        if os.path.isfile(args.classlist):
            trainer.logger.experiment.log_artifact(args.classlist, name=os.path.basename(args.classlist), block=True)
        if os.path.isfile(args.vallist):
            trainer.logger.experiment.log_artifact(args.vallist, name=os.path.basename(args.vallist), block=True)
        if os.path.isfile(args.knnlist):
            trainer.logger.experiment.log_artifact(args.knnlist, name=os.path.basename(args.knnlist), block=True)

    # DO TRAINING #
    trainer.fit(model, datamodule=datamodule)

    # Copy best model
    # TODO do this as a callback
    if trainer.logger.experiment.artifacts_uri:
        model_path = trainer.checkpoint_callback.best_model_path
        trainer.logger.experiment.log_artifact(model_path, name=os.path.basename(model_path), block=True)

    print('DONE!')

if __name__ == '__main__':
    parser = argparse_init()
    args = parser.parse_args()
    argparse_runtime_args(args)
    main(args)